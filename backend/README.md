# ğŸ“Œ SLM Model Builder Backend

JSON ê¸°ë°˜ìœ¼ë¡œ **ì†Œí˜• ì–¸ì–´ ëª¨ë¸(SLM)** êµ¬ì¡°ë¥¼ ì„¤ê³„í•˜ê³ , í•™ìŠµ ë° ì¶”ë¡ ê¹Œì§€ ìˆ˜í–‰í•˜ëŠ” **FastAPI + Celery + Redis + MLflow** ë°±ì—”ë“œì…ë‹ˆë‹¤.

---

## ğŸ“¦ ìš”êµ¬ì‚¬í•­

- **Python 3.10+**
- **Redis ì„œë²„** (`redis-server`)
- **PyTorch** (CPU ë˜ëŠ” CUDA í™˜ê²½ì— ë§ê²Œ ì„¤ì¹˜)
- **MLflow** (ì‹¤í—˜ ë° ë¡œê·¸ ê´€ë¦¬)
- (ì„ íƒ) **GPU í™˜ê²½ ê¶Œì¥**

---

## ğŸ“¥ ì„¤ì¹˜ ë°©ë²•

```bash
git clone <this-repo-url>
cd <this-repo-name>

python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

pip install -r requirements.txt

```

## ì‹¤í–‰ ìˆœì„œ

```bash
# 1) ê°€ìƒí™˜ê²½ + ì„¤ì¹˜
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# 2) MLflow UI
mlflow ui --host 127.0.0.1 --port 5000

# 3) Redis
redis-server
# í•„ìš” ì‹œ ì´ˆê¸°í™”: redis-cli flushall

# 4) Celery Worker
celery -A celery_worker.celery_app worker --loglevel=info

# 5) FastAPI
uvicorn main:app --reload
```

## ğŸ“¥ API ì‚¬ìš©ë²•

---

### 1ï¸âƒ£ í•™ìŠµ ì‹œì‘ â€” `POST /api/v1/train-complete-model`

ëª¨ë¸ êµ¬ì¡° ê²€ì¦ â†’ êµ¬ì¡° ì €ì¥ â†’ MLflow ëŸ° ìƒì„± â†’ Celery í•™ìŠµ íƒœìŠ¤í¬ ì‹œì‘ â†’ SSEë¡œ ì§„í–‰ìƒí™© ìŠ¤íŠ¸ë¦¬ë°

```bash
curl -X POST http://127.0.0.1:8000/api/v1/train-complete-model \
  -H "Content-Type: application/json" \
  -d @request.json

  request.json ì˜ˆì‹œ

  "config": {
    "model": "gpt-2",
    "epochs": 1,
    "batch_size": 2,
    "vocab_size": 50257,
    "context_length": 32,
    "emb_dim": 128,
    "n_heads": 2,
    "n_blocks": 1,
    "drop_rate": 0.1,
    "qkv_bias": false,
    "dtype": "fp32"
  },
  "model": [
    { "type": "tokenEmbedding", "data": { "id": "tok", "vocabSize": 50257, "embDim": 128 } },
    { "type": "positionalEmbedding", "data": { "id": "pos", "ctxLength": 32, "embDim": 128, "mode": "learned" } },
    { "type": "linear", "data": { "id": "head", "inDim": 128, "outDim": 50257 } }
  ],
  "dataset": "tiny_shakespeare",
  "dataset_config": "default",
  "modelName": "ex1"
}

âœ… ì„±ê³µ ì‘ë‹µ ì˜ˆì‹œ

json
{
  "status": "success",
  "task_id": "abc123",
  "sse_url": "/api/v1/events/abc123",
  "sse_url_abs": "http://127.0.0.1:8000/api/v1/events/abc123",
  "stop_url_abs": "http://127.0.0.1:8000/api/v1/stop-training",
  "mlflow_url": "http://127.0.0.1:5000/#/experiments/1/runs/run123",
  "message": "ëª¨ë¸ ê²€ì¦/ìƒì„±/êµ¬ì¡°ì €ì¥/MLflow ëŸ° ìƒì„± í›„ í•™ìŠµì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ì§„í–‰ìƒí™©ì€ SSEë¡œ ì „ì†¡ë©ë‹ˆë‹¤."
}
```

2ï¸âƒ£ ì§„í–‰ìƒí™© ìŠ¤íŠ¸ë¦¬ë° â€” GET /api/v1/events/{task_id}
í•™ìŠµ ì´ë²¤íŠ¸(connected, started, step, progress, status, finished, error)ë¥¼ ì‹¤ì‹œê°„ í‘¸ì‹œ
15ì´ˆë§ˆë‹¤ í•˜íŠ¸ë¹„íŠ¸(: keep-alive) ì „ì†¡

```bash


curl -N http://127.0.0.1:8000/api/v1/events/<TASK_ID>


data: {"event":"connected","data":{"channel":"task:<TASK_ID>"}}
data: {"event":"started","data":{"task_id":"<TASK_ID>","model_name":"ex1","run_id":"<RUN_ID>","mlflow_url":"http://127.0.0.1:5000/#/experiments/1/runs/<RUN_ID>","epochs":1,"batch_size":2,"context_length":32,"stride":16}}
data: {"event":"step","data":{"task_id":"<TASK_ID>","global_step":10,"epoch":1,"loss":2.3451,"ema_loss":2.2103}}
data: {"event":"progress","data":{"task_id":"<TASK_ID>","epoch":1,"epochs":1,"avg_epoch_loss":2.10,"train_loss":2.05,"val_loss":2.40,"global_step":120,"run_id":"<RUN_ID>"}}
data: {"event":"status","data":{"task_id":"<TASK_ID>","state":"running","epoch":1,"global_step":120}}
data: {"event":"finished","data":{"task_id":"<TASK_ID>","model_name":"ex1","run_id":"<RUN_ID>","completed_model_path":"completed/ex1.pt","last_train_loss":2.05,"last_val_loss":2.40,"status":"finished","ts":1720000000.0}}
```

3ï¸âƒ£ í•™ìŠµ ì¤‘ë‹¨ â€” POST /api/v1/stop-training

í˜‘ë ¥ì (cooperative) ì¤‘ë‹¨ì´ ê¸°ë³¸, force_kill=true ì‹œ í•˜ë“œ ì¢…ë£Œ(SIGTERM)

```bash

curl -X POST http://127.0.0.1:8000/api/v1/stop-training \
  -H "Content-Type: application/json" \
  -d '{"task_id":"<TASK_ID>", "force_kill": false}'


âœ… ì‘ë‹µ ì˜ˆì‹œ

{
  "status": "ok",
  "task_id": "<TASK_ID>",
  "celery_state": "STARTED",
  "mode": "cooperative_stop",
  "message": "Stop requested (flag set)."
}

```

4ï¸âƒ£ ì™„ë£Œ ëª¨ë¸ ëª©ë¡ â€” GET /api/v1/completed-models

```bash
curl http://127.0.0.1:8000/api/v1/completed-models


âœ… ì‘ë‹µ ì˜ˆì‹œ

{
  "models": [
    { "model_name": "ex1", "has_structure": true,  "structure_file": "ex1.json" },
    { "model_name": "ex2", "has_structure": false, "structure_file": null }
  ]
}

```

5ï¸âƒ£ í…ìŠ¤íŠ¸ ìƒì„±(ì¶”ë¡ ) â€” POST /api/v1/generate-text

```bash
curl -X POST http://127.0.0.1:8000/api/v1/generate-text \
  -H "Content-Type: application/json" \
  -d '{"model_name":"ex1","input_text":"Once upon a time","max_length":50,"temperature":0.7,"top_k":40}'


âœ… ì‘ë‹µ ì˜ˆì‹œ

{
  "status": "success",
  "input_text": "Once upon a time",
  "output_text": "Once upon a time ... (ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸)"
}

```
